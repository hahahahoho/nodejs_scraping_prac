# Scraping 실전

#### Web Scraping : 컴퓨터 소프트웨어 기술로 웹 사이트들에서 원하는 정보를 추출하는 것을 의미합니다.

이전에 올린 scraping_basic에서는 스크래핑에 대한 상세한 설명과 어떻게 구현할 것인지 보다는 스크래핑에 대한 간략한 이해와 어떻게 웹사이트를 불러와 스크래핑을 할 수 있는지에 대한 설명을 하였습니다.

이번에는 좀 더 스크래핑에 대한 구체적인 설명과 어떻게 코드를 짰는지, 그리고 활용방안에 대해서 얘기 하겠습니다. 코드는 많이 미숙합니다. ㅠㅠ 혹시 더 효율적으로 짤 수 있는 방법을 알고 계신다면 꼭 피드백 받고 싶습니다!.

무튼, 스크래핑이란 위에서 말한 것 처럼 컴퓨터 소프트웨어 기술로 웹 사이트에서 원하는 데이터를 추출하는 것을 의미합니다. 

파이썬에는 beautiful_soup라는 라이브러리가 있습니다. 스크래핑을 편안하게 해줄 아주 유용한 도구죠. nodejs에는 비슷한 기능을 하는 라이브러리를 찾기 힘들었습니다. 그래서! 파이썬에서 제공하는 beautiful_soup라는 라이브러리와 같이 비슷한 기능을 낼 수 있도록 직접 만들어봤습니다.

먼저, 만들면서 가장 중요하게 생각한 부분입니다.

1. ##### 스크래핑이란 기본적으로 분명한 목적이 있어야 합니다.

   -> 크롬 검색기를 이용하여 직접 서칭하여 데이터를 찾겠다. 또는 어떤 홈페이지에서 url주소를 통하여 이동하는 데이터들의 정보를 찾겠다와 같이 분명한 목적이 있어야 합니다. 이번에는 간단하게 url패턴을 통해 원하는 데이터를 가져올 것입니다.

   **사실 목적에 맞는 알고리즘을 적용할 수 있으면, 구글과 같이 웹사이트들을 자동으로 돌아다니면서 원하는 데이터를 가져올 수도 있겠지만 이 부분은 제가 설명드릴 수 없는 부분이라 생략하겠습니다. ㅜ

2. ##### 패턴을 분석하여 그에 맞게 코드를 짜야 합니다. 

   ->예를 들어, 한 페이지를 크롤링한다고 가정합니다. 그 웹페이지는 어지러운 듯 보이지만 데이터를 넣는 태그에서 일정한 규칙을 찾을 수 있을 겁니다. 반복문을 통해 출력되는 구조라던가 class이름, data속성 이름, css 등을 통해 규칙을 찾을 수 있습니다. 우리는 이제 규칙을 통해 코드를 작성하여 원하는 데이터를 가져와야 합니다.



이제 코드를 보면서 설명드리겠습니다.

```
var app = require('./scrapper');

let url = 'http://www.soribada.com/cs/list_view/';
let title = {"class" : "viewTitleFont"}; 
let contents = {"class" : "viewContent"};
let params =  [title, contents];

//*[@id="toc"]/ul/li[3] //xpath
// document.querySelector('#toc > ul > li:nth-child(3)')
// #toc > ul > li:nth-child(3)
let url02 = "http://www.soribada.com/cs/lists/member/1";
app.init();
for(var i = 0; i<15 ; i++){
    target_url = url+i;
    app.url(target_url);
    let test = app.scraping_type_attr(params).filter_tag([{'viewTitleFont' : 'span'}]).read();
    console.log(i+'page : ', test);
}
//app.readAll();
```

scrapper.js는 제가 만든 스크래핑 모듈파일입니다. 함께 올려놓았으니 확인하시고 편한대로 사용하시면 되겠습니다 ^^. 

지금은 class, id, name, data속성을 찾아서 원하는 데이터를 가져오는 것만 되는데 조만간 xpath를 이용한 태그구조를 통해 데이터를 가져오는 기능과, text를 확인하여 데이터를 가져오는 기능을 추가 할 것 입니다. 그리고 최종적으로 구글 등과 같은 검색엔진을 통해 원하는 내용을 입력하여 검색하고 검색 된 내용의 페이지의 정보를 가져오는 것도 추가하겠습니다.

- init() : 모듈 초기화 작업을 합니다.
- url(param : string) : 원하는 웹페이지 주소를 입력 받고 셋팅합니다.
- scraping_type_attr(param : [ {'속성명', '값'} ]) : 객체로 담겨진 배열을 받아 원하는 데이터를 스크래핑하여 결과값을 저장합니다.
- filter_tag( [{'속성값' : 'tag명'}] ) : 앞에서 스크래핑한 결과값 중 원하는 속성값을 가진 태그와 작성한 태그가 일치한지 아닌지 판별 후 아닐 경우 삭제, 일치할 경우 넘어갑니다. 
- read() : 페이지를 스크래핑 할 때마다 최근 추가된 결과값만 배열형태로 리턴합니다.
- readAll() : 모든 페이지 결과 값을 배열로 저장하여 한번에 리턴합니다.

스크래핑을 만들면서 가장 헷갈렸던 점은 this객체 입니다. 일반적인 javascript에서의 this객체와 nodejs에서의 객체는 조금 달랐습니다.  이 부분은 저도 이해만 어느정도 한 것이라 자세하게 설명은 못드리겠네요.. ㅜ 

this에 대해서 정확히 알면 앞으로 코드작성할 때 정말 좋은 점과 효율성이 높아지니 꼭 찾아보셔서 본인의 것으로 만드셨으면 하는 바램입니다.

